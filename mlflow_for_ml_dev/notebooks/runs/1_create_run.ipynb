{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./images/mlflow_run.jpeg\" alt=\"MLFlow Run\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "A MLflow run is a unit of work in MLflow that represents the execution of a machine learning experiment or a piece of code. It tracks the parameters, metrics, artifacts, and metadata associated with the run. MLflow runs allow you to log and track experiments, compare different runs, and reproduce results. Each run is associated with an experiment and can have multiple tags, parameters, metrics, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a MLflow Run\n",
    "\n",
    "### Using start_run\n",
    "\n",
    "```python\n",
    "mlflow.start_run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the experiment name and tags\n",
    "experiment_name = \"runs-01\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment = get_or_create_experiment(experiment_name, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Experiment name: {experiment.name}\")\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting an Active Run.\n",
    "\n",
    "An active MLflow run is a session where MLflow tracks and logs relevant data about the machine learning model training process. This includes logging parameters, metrics, artifacts (like models or plots), and metadata in real time. A run begins when the mlflow.start_run() function is called and remains active until mlflow.end_run() is executed. During this period, any logged information will be associated with the run, which is identified by a unique run ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the type of the run object\n",
    "print(f\"Object Type: '{type(run).__name__}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating a machine Learning run\n",
    "\n",
    "# Machine learing code here\n",
    "# ...\n",
    "\n",
    "# logging some random parameters\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "mlflow.log_param(\"param2\", 5)\n",
    "mlflow.log_param(\"param3\", 5)\n",
    "\n",
    "# logging some random metrics\n",
    "mlflow.log_metric(\"metric1\", 15)\n",
    "mlflow.log_metric(\"metric2\", 52)\n",
    "mlflow.log_metric(\"metric3\", 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the updated run object. This method will return the updated run object\n",
    "run = mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !Error: \n",
    "\n",
    "Before creating a new active run is necessary to end any previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run without ending the previous one will throw an error\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start a new run, first end the current run with mlflow.end_run().\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing more run metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the experiment name and tags\n",
    "experiment_name = \"runs-01\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment = get_or_create_experiment(experiment_name, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating run providing more info. Such as run name, description and tags.\n",
    "run_tags = {\"tag1\": \"value1\", \"tag2\": \"value2\"}\n",
    "\n",
    "run3 = mlflow.start_run(\n",
    "    run_name=\"run_with_tags\",\n",
    "    tags=run_tags,\n",
    "    description=\"This is a run with tags\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ending the run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> About `mlflow.start_run()`\n",
    "> \n",
    "> The return value of `mlflow.start_run()` can be used as a context manager within a `with` block. Otherwise, you must call `end_run()` to terminate the current run.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Log metrics and params\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlflow.tracking.fluent.ActiveRun'>\n",
      "Active Run:  8ec23e31aa7947099f77aafc894fbf21\n",
      "Active Run:  8ec23e31aa7947099f77aafc894fbf21\n",
      "\n",
      " \n",
      "\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# mlflow.end_run() # end the active run to start a new one\n",
    "with mlflow.start_run(run_name=\"Run 2\", experiment_id=experiment.experiment_id) as run:\n",
    "\n",
    "    # Your ML code here\n",
    "    # ...\n",
    "    \n",
    "    active_run = mlflow.active_run()\n",
    "    print(type(active_run))  \n",
    "    print(\"Active Run: \", run.info.run_id)\n",
    "    print(\"Active Run: \", active_run.info.run_id)\n",
    "    print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "# outside the with block\n",
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# active_run is None because the run has ended.\n",
    "active_run == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mlflow client\n",
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a run with the specified name and tags\n",
    "created_run = client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    "    run_name=\"test_run\",\n",
    "    tags = {\n",
    "        \"tag1\": \"value1\",\n",
    "        \"tag2\": \"value2\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the run is of type mlflow.entities.Run. Before it was of type mlflow.entities.ActiveRun\n",
    "type(created_run).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the client creates a Run object, there will be no active run. (ActiveRun is a different object)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.tracking.fluent.ActiveRun"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loging to MLflow without an active run will create a new run automatically. \n",
    "# Some mlflow functions create a run automatically if there is no active run.\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bright-sloth-381'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random name created by mlflow\n",
    "run.info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the active run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_run\n"
     ]
    }
   ],
   "source": [
    "# We can resume the run by providing the run_id and then log into it \n",
    "with mlflow.start_run(run_id = created_run.info.run_id):\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    run = mlflow.active_run()\n",
    "    print(run.info.run_name)\n",
    "\n",
    "# This will also end the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a second run with the mlflow client\n",
    "created_run = client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    "    run_name=\"test_run\",\n",
    "    tags = {\n",
    "        \"tag1\": \"value1\",\n",
    "        \"tag2\": \"value2\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some logging functions that allows to log into a specific run by providing the run_id\n",
    "mlflow.log_metric(key=\"metric1\", value=5, run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Although, not all logging functions have the run_id parameter.\n",
    "# For example, mlflow.log_param() does not have the run_id parameter\n",
    "mlflow.log_param(\"param1\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ending the active run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using the \"with\" block, we can use the client to terminate the run.\n",
    "client.set_terminated(run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Run Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the experiment name and tags\n",
    "experiment_name = \"runs-01\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment = get_or_create_experiment(experiment_name, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the active run to start a new one\n",
    "mlflow.end_run()\n",
    "with mlflow.start_run(run_name=\"Run 3\", experiment_id=experiment.experiment_id) as run:\n",
    "    # set a single tag\n",
    "    mlflow.set_tag(\"tag3\", \"value3\")\n",
    "    \n",
    "    # Set multiple tags as a dictionary \n",
    "    mlflow.set_tags({\"tag4\": \"value4\", \"tag5\": \"value5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update run description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can update the description of the run \n",
    "# In this case we are updating the description of the run with the name \"Run 4\"\n",
    "with mlflow.start_run(run_name=\"Run 4\", experiment_id=experiment.experiment_id) as run:\n",
    "    \n",
    "    #Update description\n",
    "    # the tag \"mlflow.note.content\" is used to store the description of the run\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"This is a new description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including markdown.\n",
    "with mlflow.start_run(run_name=\"Run 5\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"# This is a new description\")\n",
    "\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id = run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_dictionary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
