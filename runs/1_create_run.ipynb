{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./images/mlflow_run.jpeg\" alt=\"MLFlow Run\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "A MLflow run is a unit of work in MLflow that represents the execution of a machine learning experiment or a piece of code. It tracks the parameters, metrics, artifacts, and metadata associated with the run. MLflow runs allow you to log and track experiments, compare different runs, and reproduce results. Each run is associated with an experiment and can have multiple tags, parameters, metrics, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a MLflow Run\n",
    "\n",
    "### Using start_run\n",
    "\n",
    "```python\n",
    "mlflow.start_run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.utils.utils import get_root_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\projects\\mlflow_for_ml_dev\\runs\\mlruns\n"
     ]
    }
   ],
   "source": [
    "# Set the tracking uri to the mlruns folder in the root project\n",
    "# This will allow us to store run metadata in the mlruns folder in the root project\n",
    "\n",
    "artifact_location = get_root_project() / \"runs\" / \"mlruns\"\n",
    "\n",
    "mlflow.set_tracking_uri(artifact_location.as_uri())\n",
    "print(artifact_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the experiment name and tags\n",
    "experiment_name = \"runs-01\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "\n",
    "# Create an experiment\n",
    "experiment_id = mlflow.create_experiment(name=experiment_name, tags=tags)\n",
    "\n",
    "# Set the experiment. This will allow us to log runs to the experiment\n",
    "# It returns an experiment object\n",
    "experiment = mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting an Active Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.tracking.fluent.ActiveRun"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the type of the run object\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id: \"5ac5be251aed48b485e838b89863676d\"\n",
       "run_uuid: \"5ac5be251aed48b485e838b89863676d\"\n",
       "run_name: \"rare-gnu-461\"\n",
       "experiment_id: \"594575729744005488\"\n",
       "user_id: \"manue\"\n",
       "status: RUNNING\n",
       "start_time: 1721091394319\n",
       "artifact_uri: \"file:///C:/Users/manue/projects/mlflow_for_ml_dev/runs/mlruns/594575729744005488/5ac5be251aed48b485e838b89863676d/artifacts\"\n",
       "lifecycle_stage: \"active\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': {},\n",
       " 'params': {},\n",
       " 'tags': {'mlflow.runName': 'rare-gnu-461',\n",
       "  'mlflow.source.name': 'c:\\\\Users\\\\manue\\\\projects\\\\mlflow_for_ml_dev\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       "  'mlflow.source.type': 'LOCAL',\n",
       "  'mlflow.user': 'manue'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating a machine Learning run\n",
    "\n",
    "# Machine learing code here\n",
    "# ...\n",
    "\n",
    "# logging some random parameters\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "mlflow.log_param(\"param2\", 5)\n",
    "mlflow.log_param(\"param3\", 5)\n",
    "\n",
    "# logging some random metrics\n",
    "mlflow.log_metric(\"metric1\", 15)\n",
    "mlflow.log_metric(\"metric2\", 52)\n",
    "mlflow.log_metric(\"metric3\", 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the updated run object. This method will return the updated run object\n",
    "run = mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': {'metric1': 15.0, 'metric2': 52.0, 'metric3': 35.0},\n",
       " 'params': {'param1': '5', 'param2': '5', 'param3': '5'},\n",
       " 'tags': {'mlflow.runName': 'rare-gnu-461',\n",
       "  'mlflow.source.name': 'c:\\\\Users\\\\manue\\\\projects\\\\mlflow_for_ml_dev\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       "  'mlflow.source.type': 'LOCAL',\n",
       "  'mlflow.user': 'manue'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 5ac5be251aed48b485e838b89863676d is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#starting a new run without ending the previous one will throw an error\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m run2 \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\projects\\mlflow_for_ml_dev\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:306\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    304\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    307\u001b[0m         (\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 5ac5be251aed48b485e838b89863676d is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "#starting a new run without ending the previous one will throw an error\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start a new run, first end the current run with mlflow.end_run().\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing more run metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating run providing more info. Such as run name, description and tags.\n",
    "run_tags = {\"tag1\": \"value1\", \"tag2\": \"value2\"}\n",
    "\n",
    "run3 = mlflow.start_run(\n",
    "    run_name=\"run_with_tags\",\n",
    "    tags=run_tags,\n",
    "    description=\"This is a run with tags\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ending the run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> About `mlflow.start_run()`\n",
    "> \n",
    "> The return value of `mlflow.start_run()` can be used as a context manager within a `with` block. Otherwise, you must call `end_run()` to terminate the current run.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Log metrics and params\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlflow.tracking.fluent.ActiveRun'>\n",
      "Active Run:  003df1628d2f4667b8ac40ffd97fc629\n",
      "Active Run:  003df1628d2f4667b8ac40ffd97fc629\n",
      "\n",
      " \n",
      "\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run() # end the active run to start a new one\n",
    "with mlflow.start_run(run_name=\"Run 2\", experiment_id=experiment.experiment_id) as run:\n",
    "\n",
    "    # Your ML code here\n",
    "    # ...\n",
    "    \n",
    "    active_run = mlflow.active_run()\n",
    "    print(type(active_run))  \n",
    "    print(\"Active Run: \", run.info.run_id)\n",
    "    print(\"Active Run: \", active_run.info.run_id)\n",
    "    print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "# outside the with block\n",
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# active_run is None because the run has ended.\n",
    "active_run == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mlflow client\n",
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a run with the specified name and tags\n",
    "created_run = client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    "    run_name=\"test_run\",\n",
    "    tags = {\n",
    "        \"tag1\": \"value1\",\n",
    "        \"tag2\": \"value2\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.entities.run.Run"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the run is of type mlflow.entities.Run. Before it was of type mlflow.entities.ActiveRun\n",
    "type(created_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the client creates a Run object, there will be no active run. (ActiveRun is a different object)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.tracking.fluent.ActiveRun"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loging to MLflow without an active run will create a new run automatically. \n",
    "# Some mlflow functions create a run automatically if there is no active run.\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rogue-ant-685'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random name created by mlflow\n",
    "run.info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the active run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_run\n"
     ]
    }
   ],
   "source": [
    "# We can resume the run by providing the run_id and then log into it \n",
    "with mlflow.start_run(run_id = created_run.info.run_id):\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    run = mlflow.active_run()\n",
    "    print(run.info.run_name)\n",
    "\n",
    "# This will also end the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a second run with the mlflow client\n",
    "created_run = client.create_run(\n",
    "    experiment_id=experiment.experiment_id,\n",
    "    run_name=\"test_run\",\n",
    "    tags = {\n",
    "        \"tag1\": \"value1\",\n",
    "        \"tag2\": \"value2\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some logging functions that allows to log into a specific run by providing the run_id\n",
    "mlflow.log_metric(key=\"metric1\", value=5, run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Although, not all logging functions have the run_id parameter.\n",
    "# For example, mlflow.log_param() does not have the run_id parameter\n",
    "mlflow.log_param(\"param1\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ending the active run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using the \"with\" block, we can use the client to terminate the run.\n",
    "client.set_terminated(run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Run Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the active run to start a new one\n",
    "mlflow.end_run()\n",
    "with mlflow.start_run(run_name=\"Run 3\", experiment_id=experiment.experiment_id) as run:\n",
    "    # set a single tag\n",
    "    mlflow.set_tag(\"tag3\", \"value3\")\n",
    "    \n",
    "    # Set multiple tags as a dictionary\n",
    "    mlflow.set_tags({\"tag4\": \"value4\", \"tag5\": \"value5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update run description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can update the description of the run \n",
    "# In this case we are updating the description of the run with the name \"Run 4\"\n",
    "with mlflow.start_run(run_name=\"Run 4\", experiment_id=experiment.experiment_id) as run:\n",
    "    \n",
    "    #Update description\n",
    "    # the tag \"mlflow.note.content\" is used to store the description of the run\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"This is a new description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including markdown.\n",
    "with mlflow.start_run(run_name=\"Run 5\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"# This is a new description\")\n",
    "\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run 5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id = run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id: \"1addb617ee694576b415fb3883047820\"\n",
       "run_uuid: \"1addb617ee694576b415fb3883047820\"\n",
       "run_name: \"Run 5\"\n",
       "experiment_id: \"594575729744005488\"\n",
       "user_id: \"manue\"\n",
       "status: FINISHED\n",
       "start_time: 1721093472082\n",
       "end_time: 1721093472143\n",
       "artifact_uri: \"file:///C:/Users/manue/projects/mlflow_for_ml_dev/runs/mlruns/594575729744005488/1addb617ee694576b415fb3883047820/artifacts\"\n",
       "lifecycle_stage: \"active\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': {'metric1': 15.0},\n",
       " 'params': {'param1': '5'},\n",
       " 'tags': {'mlflow.note.content': '# This is a new description',\n",
       "  'mlflow.runName': 'Run 5',\n",
       "  'mlflow.source.name': 'c:\\\\Users\\\\manue\\\\projects\\\\mlflow_for_ml_dev\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       "  'mlflow.source.type': 'LOCAL',\n",
       "  'mlflow.user': 'manue'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.to_dictionary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
